

\documentclass[conference]{IEEEtran}
\ifCLASSINFOpdf
   \usepackage[pdftex]{graphicx}
\else

\fi
\usepackage[cmex10]{amsmath}
\usepackage{amssymb}
\usepackage{url}
\usepackage[caption=false,font=footnotesize]{subfig}
\hyphenation{op-tical net-works semi-conduc-tor}
\usepackage{subscript}
\usepackage{dsfont}


\begin{document}


\title{KNN classifier with self adjusting memory for heterogenous concept drift }


\author{\IEEEauthorblockN{Viktor Losing\IEEEauthorrefmark{1}\IEEEauthorrefmark{2},
Barbara Hammer\IEEEauthorrefmark{1} and
Heiko Wersing\IEEEauthorrefmark{2}}
\IEEEauthorblockA{\IEEEauthorrefmark{1}Bielefeld University, Universit\"atsstr. 25, 33615 Bielefeld}
\IEEEauthorblockA{\IEEEauthorrefmark{2}HONDA Research Institute Europe, Carl-Legien-Str. 30, 63073 Offenbach am Main}
}



\maketitle


\setcounter{figure}{0}
\begin{abstract}
Learning from non-stationary data streams is gaining more attention
recently, especially in the context of Internet of Things and Big Data.
It is a highly challenging task, since the fundamentally different types
of possibly occurring drift undermine classical assumptions such as
i.i.d data. Incremental drift characterizes a continuous change in the
distribution such as the signals of a slowly degrading sensor. A
suddenly malfunctioning sensor on the other hand causes a severe shift
and is defined as abrupt drift. Available algorithms are able to handle
different types of drift, however they target either abrupt or
incremental drift and often incorporate hyperparameter requiring a
priori knowledge about the task at hand.\\
We propose a biological inspired, architecture which partitions the data
into a short-term and long-term memory. The former is a window of
recently seen data-points whose size is adjusted such that the estimated
generalization error is minimized. The latter preserves only those
information from previous concepts which are non-conflicting to the
current one. These memories are combined according to the demands of the
present concept to classify unseen data points. We couple our parameter
free approach with the K-Nearest Neighbor classifier, however, any other
incremental learning algorithm could be used as well. \\
New artificial and real datasets are proposed to evaluate performance on
specific types of drift. Experiments on these as well as on generally
known benchmark datasets compare our approach with state of the art
methods. The highly competitive results throughout all experiments
underline the robustness of our approach.
\end{abstract}

\IEEEpeerreviewmaketitle

\section{Introduction}
\section{Concept Drift}
Definition and examples
\subsection{Types of Drift}
-abrupt, incremental, gradual, reoccuring, virtual
\section{Related Work}
-Survey by gamma eventuell Ditzler
-Active drift detection work Gamma, Bifet ADWIN for abrupt to minimize delay
-Passive drift handling with ensembles DACC, LPPNSE
-Windowing but usually throws away information which still can be valid, no LTM
  -SVM Leave one out
  -KNNPAW 
-KNN for streaming like the ICDM paper


\section{Architecture}
XXVL biological motivation.... search article to STM and LTM for humans etc.
Our architecture is depicted in figure \ref{XXVL}. It consists of 4 different steps. 
In contrast to various other methods that only adapt the size of the sliding window, using either a heuristic \cite{XXVL} or optimize a given criteria \cite{XXVL} 
our approach preserves knowledge of former concepts which may still be valid. This is especially useful in the case of virtual or reoccuring drift.
Thereby we use two different type of memories the Short Term Memory (STM) and the Long Term Memory(LTM). The STM is a sliding window of dynamic size, adjusted such that the
estimated generalization error is minimized and therefore contains the current concept.
The LTM preserves all knowledge of former concepts which is not in conflict with the current one. We share the common assumption of the most recent examples
being the closest to new examples. Therefore, it is crucial to ensure that the information in the LTM is not contradicting those in the STM. Incoming examples are predicted
by using either one memory alone or both combined, depending on the demands of the current concept. In the following we describe the architecture in detail.
XXVL general description of the algorithm
\subsection{Size adaption of the Short Term Memory}
Given a classification task of $C$ classes, an incremental algorithm generates for a dataset $X= \{ (\mathbf{x}_i,y_i) \in \mathbb{R}^n \times \{1,...,C\}\}_{i=1}^m$
a set of models $H(X)=\{h_0,..,h_{m}\}$ XXVL anmerkung zu $h_0$. The interleaved test-train error of $H$ on $X$ is 
\begin{equation*}
E(X, H) = \frac{1}{m}\sum_{i=0}^m \mathds{1} (h_{i-1}(x_i)\neq y_i).
\end{equation*}
The STM is a sliding window of size $m_1$ and for a given time $t$ defined as 
$S_1= \{ (\mathbf{x}_i,y_i) \in \mathbb{R}^n \times \{1,...,C\}\}_{i=t-m_1}^{t}$, $t, m_1<=m$.
We generate recursively a set $\Psi$, 
\begin{equation*}
\Psi=\{S_i|S_i=\{(x_{t-m_1/2^{i-1}},y_{t-m_1/2^{i-1}}),...,(\mathbf{x}_t,y_t)\}\}_{i=1}^k,
\end{equation*}
of $k$ STMs by bisection until a minimum size $l$ is reached, such that $|S_k|>=l$.
The $S_i$ minimizing the error the most is used as new STM :
\begin{equation*}
STM = arg\,min_{S_i}\,E(S_i, H(S_i)).
\end{equation*}
The Interleaved test-train error has various advantages over the commonly used test error, estimated on a seperate set. Firstly, each example is used for both testing and 
it is quite stable since the value does not depend on random splits. It is the natural choice for streaming data and can be incrementally calculated, boosting the efficiency see \ref{efficiency}.\\
Our way to adapt the size of the STM has similarities with \cite{klinkenberg2000detecting}. However, they use estimates of the leave one out error, only applicable for the Support Vector Machine
and do not specify how to choose the compared window sizes. Whereas we present an approach directly determining the interleaved test-train error on recursively bisected windows which is applicable for arbitrary models. 
\subsection{Transfer of obsolete STM points into LTM}

\subsection{Compression in the Long Term Memory}
-STM, partitioning, O(log n) tests, maximizing generalization accuracy, write down in fancy formal way
-LTM, keep not compromising
-Transfer
-choosing of proper prediction model(STM, or LTM, or Both)
-Clustering
-Size management

\subsection{Prediction responsibility}



\subsection{Efficiency}\label{efficiency}
-distances have to be calculated anyways once, can be stored and afterwards need only to be sorted. Splits are given by kleiner Gauss.
-For the Interleaved Test Train error results of the previous iteration can be used and have just to be extended. Distances, have to be calculated anyways for NN,
therefore O(log n) for the check of shrinking, which is the most complex step.
-approximative KNN
-adapt stm not every example but every n examples

\subsection{Choice of classifier}
-fits with other algorithms as long they can be trained incremental and decremental e.g. NB, incremental SVM, but how to solve validation procedure
\section{Algorithms}
We compare our method with well-known state of the art algorithms for handling drift in streaming data. Implementations of the original authors or those available in MOA \cite{bifet2010moa}
have been used to conduct the experiments. The following algorithms are considered:\\
\\\textbf{Learn++.NSE}\\
Proposed in \cite{5975223}, this algorithm processes incoming samples in chunks with a predefined size. A base classifier is trained for each chunk and added to the ensemble. The loss on recent chunks is averaged with a sigmoidal function
to compute the final weight of each base classifier. Similar to AdaBoost \cite{XXVL}, instances are weighted such that misclassified inputs have a higher impact on the calculated loss.
Chunk-wise trained models have by design an adaption delay depending on the chunk size(XXVL chunksize very crucial). The base classifier are in our case Classification and Regression Trees \cite{cart84}.
\\\textbf{Leveraging Bagging}\\
Bifet et al. propose in \cite{bifet2010leveraging} to increase the randomization of Online Bagging \cite{oza2005online} and thereby the diversity of the ensemble.
This is done by a higher $\lambda$ value for the poisson distribution and the usage of output detection codes. Additionaly, they use ADWIN as change detector for every classifier within the ensemble such that whenever a change is detected 
the worst classifier is replaced by a new one. Hoeffding Trees\cite{domingos2000mining} with Gaussian Naive Bayes within the leaves are used as base classifier.
XXVL maybe define Hoeffding trees.
\\\textbf{Dynamic Adaption of Concept Changes}\\
Within this ensemble algorithm \cite{jaber2013online} a classifier of the worst half of the pool is removed randomly after a predefined number of examples and replaced by a new one. 
Newly generated classifier are excluded for a predefined time from the elimination process. Predictions for incoming examples are solely done by the classifier within the pool which
achieved the highest accuracy in the past. As in Leavarging Bagging, Hoeffding Trees are chosen as base classifier.
\\\textbf{kNN sliding window}\\
A distance weighted kNN classifier is combined with a fixed window size containing the most recent samples. 
This so called sliding window approach is a common way for drift handling, since the window contains usually the most relevant examples
for the future predictions. However, the choice of the static size is crucial and usually has to be chosen according to the given problem. A too small window hinders the classifier to gain a low error rate,
whereas a too large window may be very slow in adapting to new concepts. 
\\\textbf{kNN with Probabilistic Adaptive Window and ADWIN}\\
In contrast to the approach FIFO principle of the sliding window approach, examples here are removed randomly leading to a mix of recent and older samples in the window. The window size is not strictly bounded 
and varies around a target size (see \cite{Bifet:2013:EDS:2480362.2480516}). This approach also uses ADWIN as change detector and clears the window (XXVL gegebenenfalls) accordingly. \\
Table \ref{tab:algorithms} gives an overview of the algorithms as well as the chosen hyperparameter. 
\begin{table}
\def\arraystretch{0.9}
\footnotesize
\centering
\caption{The compared algorithms.}
\label{tab:algorithms}
\begin{tabular}{l|cccc}
\textit{Abbr.} & Classifier & Parameter\\\hline
HT\textsubscript{A} & Hoeffding Tree with ADWIN \\
LPPNSE & Learn++.NSE with CART& chunk-Size = various\\
DACC & Dynamic with HT& n=10\\
LVGB & Leveraging Bagging with HT& n=10\\
KNN\textsubscript{S} & KNN with sliding window & w=5000, k=5\\
KNN\textsubscript{W\textsubscript{A}} & NN with PAW+ADWIN& w=5000, k=5\\
KNN\textsubscript{M} &KNN with STM+LTM memory & w=5000, k=5\\
\end{tabular}
\end{table}
A maximum of 5000 samples was allowed as size for the window based approaches. However,
we limited it to at most 10\% of the whole dataset for those with rather few examples. LPPNSE demands a chunk size which is critical for its performance. To avoid any disadvantage 
we evaluated several sizes and report the best result. No further dataset specific hyperparameter tuning was done, since we wanted to use(XXVL reinstecken)as little prior knowledge as possible.

\section{Datasets}
We used own and well known artificial as well as real world datasets for the experiments.
Links to all datasets and algorithms are available at \url{https://github.com/vlosing/Online-learning}. 
In the following we describe the data more detailed.\\

Artificial datasets have the advantage that any desired drift behavior can be explicitly simulated. They are often 
2-dimensional to enable a straightforward visualization. We evaluated ready to use published benchmark datasets as well as MOA generated ones using common parametrization in the literature.
We also added four new datasets allowing the evaluation of particular algorithm properties which are in our opinion not yet considered enough in the community. 
Table \ref{tab:artDatasets} shows their main characteristics.
\begin{table}
\caption{Evaluated artificial datasets.}
\label{tab:artDatasets}
\centering
\begin{tabular}{l|cccc}
\textit{Dataset} & \#Samples&\#Feat.&\#Class&Drift type\\\hline
SEA Concepts & 50K & 3 & 2 & abrupt\\
Rotating Hyperplane & 200K & 10 & 2 & incremental\\
Moving RBF & 200K & 10 & 5 & incremental\\
Interchanging RBF & 200K & 2 & 10 & abrupt\\
Moving Squares & 200K & 2 & 4 & incremental\\
Transient Chessboard & 200K & 2 & 8 & virtual\\
Mixed Drift & 600K & 2 & 8 & abr/incr/virt\\
\end{tabular}
\end{table}
\\\textbf{SEA Concepts}\\
This dataset was proposed in \cite{Street:2001:SEA:502512.502568} and consists of 50000 samples with three attributes of which only two are relevant.
The two class decision boundary is given by $f_1 + f_2 = \theta$, where $f_1$ and $f_2$ are the two relevant features and $\theta$ a predefined threshold.
Abrupt drift is simulated with four different concepts, by changing the value of $\theta$ every 12500 samples.
This dataset includes also 10\% of noise.\\
\textbf{Rotating Hyperplane}\\
A hyperplane in d-dimensional space is defined by the set of points $x$ that satisfy $\sum_{i=1}^{d}w_ix_i=w_0$. The position and orientation of the hyperplane
are changed incrementally by continuously adding a term $\delta$ to the weights $w_i=w_i+\delta$. 
We used the Random Hyperplane generator in MOA with the same parameters as in \cite{Bifet:2013:EDS:2480362.2480516} (10 dimensions, 2 classes, $\delta$=0.001).\\ 
\textbf{Moving RBF}\\
Gaussian distributions with random initial positions, weights and standard deviations are moved with constant speed $v$ in d-dimensional speed. 
The weight controls the partitioning of all samples among the Gaussians.
We used the Random RBF generator in MOA with the same parameters as in \cite{Bifet:2013:EDS:2480362.2480516} (10 dimensions, 50 Gaussians, 5 classes, $v$=0.001).\\ 
\textbf{Interchanging RBF}\\
Twenty Gaussians with random covariance matrix are exchanging positions every $2000$ samples. Thereby, the number of Gaussians switching their position is increased each time by one
starting from two. This generates abrupt drift of increasing strength allowing to evalute the sensitivity of a given algorithm.\\ 
\textbf{Moving Squares}\\
Four equidistantly seperated squared uniform distributions are moving in horizontal direction with constant speed. The direction is inverted whenever the leading squares reaches a predefined boundary.
Each square is representing a different class. 
The nice property of this dataset is that the upper bound of stored recent examples before old samples may start to  overlap current ones can be easily calculated (120) and  
facilitates the analysation of algorithms, especially those using a sliding window approach, for incremental drift.\\
\textbf{Transient Chessboard}\\
Virtual drift is generated by revealing successively parts of a chessboard. This is done square by square randomly chosen from the whole chessboard such that each 
each square is representing an own concept. Every four revealed fields, samples covering the whole feature space are presented. 
This alternation penalizes algorithms simply forgetting former concepts. To reduce the impact of classification by chance we used eight classes per chessboard row.\\ 
\textbf{Mixed Drift} \\
The datasets interchanging RBF, moving squares and transient chessboard are simply positioned next to each other and samples of these are alternately introduced.
Therefore, incremental, abrupt and virtual drift are occurring at the same time, requiring a local adaptation of an classifier to different drift types.\\

Unfortunately, only a few real world drift benchmarks are available, of which we used the largest ones. Additionally, we contribute two new challenging datasets obtained from visual data.
The characteristics of all considered real world datasets are given in Table \ref{tab:realDatasets}.
\begin{table}
\caption{Considered real world datasets. The drift type was determined as described in \ref{driftType}.}
\label{tab:realDatasets}
\centering
\begin{tabular}{l|cccc}
\textit{Dataset} & \#Samples&\#Feat.&\#Class&Drift type\\\hline
Weather & 18159 & 8 & 2 & virtual\\
Elec2 & 27549 & 6 & 2 & real\\
Cover Type & 581012 & 54 & 784 & real\\
Outdoor & 4000 & 21 & 40 & real\\
Railto & 40000 & 27 & 10 & real\\
\end{tabular}
\end{table}
\\\textbf{Weather}\\
Elwell et al. introduced this dataset in \cite{5975223}. Using eight different features such as temperature, pressure wind speed etc. the target is to predict 
whether it is going to rain on a certain day or not at the Offutt Air Force Base in Bellevue, Nebraska.
A period of 50 years is covered (1949-1999) summing up to 18159 samples with an imbalance towards no rain ($69\%$).\\
\textbf{Electricity market dataset (Elec2)}\\
This problem is often used as a benchmark for concept drift classification. Initially described in \cite{harries1999splice}, it was used thereafter for several performance comparisons \cite{baena2006early}, \cite{kuncheva2008adaptive}, \cite{Bifet:2013:EDS:2480362.2480516}, \cite{gama2004learning}. 
A critical note to its suitability as a benchmark can be found in \cite{zliobaite2013good}.
The dataset holds information of the Australian New South Wales Electricity Market, whose prices are affected by supply and demand. 
Each sample characterized by attributes such as day of week, timestamp, market demand etc. refers to a period of 30 minutes and the class label identifies the relative change (higher or lower) compared to the last 24 hours.
The dataset is often termed Elec2 and contains 45312 samples. However, we removed those with missing values such that 27449 points remained.\\
\textbf{Forest Cover Type}\\
Assigns cartographic variables such as elevation, slope, soil type asf of $30 \times 30$ meter cells to different forest cover types. 
Only forests with minimal human-caused disturbances were used, so that resulting forest cover types are more a result of ecological processes.
It is often used as a benchmark for drift algorithms \cite{Bifet:2013:EDS:2480362.2480516}, \cite{gama2003accurate}, \cite{oza2001experimental}.\\
\textbf{Outdoor Objects}\\
This visual dataset was obtained from images recorded by a mobile robot approaching 40 different objects in a garden environment \cite{losing2015interactive}. The lighting conditions between 
the approaches are varying significantly caused by different weather conditions and/or cast shadows as can be seen in Figure \ref{XXVL}.
Each approach consists of 10 images and is represented in temporal order within the dataset. The objects are encoded in a normalized 21-dimensional rg-chromaticity histogram.\\
\textbf{Railto Bridge Timelapse}\\
Ten of the colorful buildings next to the famous rialto bridge in Venice are encoded in a normalized 27-dimensional rgb histogram. 
The images were obtained from timelapse videos of 10 consecutive days recorded in may 2016 by a webcam of XXVL. 
Continuously changing weather and lighting conditions affect the representation  XXVL see figures. We excluded overnight recordings since they were too dark for being useful.
Figure \ref{XXVL} shows some examples recorded at different times of day.
\subsection{Assessing the drift type in real world data}\label{driftType}
While drift is explicitly generated in artificial datasets, it is rather difficult to identify the drift type or whether drift is present at all in real world data. Therefore, it is usually
assumed in the comunity that there is some drift contained in the commonly evaluated datasets. We propose in this section a method which is able to determine the present drift type in a 
given dataset. To the best of our knowledge this has not been done so far in literature. Our two staged approach can distinguish between real, virtual or no drift at all. 
In the first step we conclude whether real drift is present. If that is not the case, we continue with the second step which detects virtual drift. 
No drift is present at all whenever both tests are negative. We use sliding windows of various sizes for this analysis. 
Even though the type of classifier is interchangeable, we utilize once again KNN.\\

\subsubsection{Test for real drift}
The idea for the first step is inspired by the observation that whenever real drift is present, sliding windows of smaller sizes tend to deliver higher accuracies than larger ones. 
This contradicts the classical assumption for stationary datasets as stated in the PAC model (XXVL reference!), that the error rate of a learning algorithm decreases
with increasing number of examples. 
However, streaming data containing real drift is not stationary and more mistakes are done whenever outdated data is in conflict with samples of the current concept. 
A window which contains less of the outdated samples, delivers therefore a better result.
We test whether the accuracies achieved with sliding windows of different sizes are significantly higher than the one obtained without any size restriction. 
To obtain multiple accuracies for a given window size bootstrapped samples of the dataset maintaining the initial inherent order are generated. 
Afterwards, we perform a one sided hypothesis test with the a p-value of XXVL\%.
The method is described exemplary for one window size s1 in the following.\\
XXVL make more general and analytic!
Given a dataset X with n examples, we generate b bootstrap samples $\Psi=\hat{X}_1,\hat{X}_2...{X}_b$of the dataset and sort them such that the initial order in the dataset is preserved. 
We train a classifier with window size $s_1$ and another one with $s_n$ using $\Psi$ and asses their accuracies $a_1,a_2,...a_b$ and $\tilde{a}_1,\tilde{a}_2,...\tilde{a}_b$ respectively.  
The pth percentile of all accuracy differences $d_i = a_i - \tilde{a}_i$ is calculated. The null hypothesis, accuracy $a_i <= \tilde{a}_i$, is rejected if its value is smaller 0.\\
\subsubsection{Test for virtual drift}
In case of no real drift, we proceed with the second step and test for virtual drift. Here we permute the dataset each time before generating the bootstrapped samples and compare
the resulting accuracies with those obtained in the first stage using the same window size. The permutation mixes data of all concepts. If P(X) is changed over time an 
algorithm should achieve higher accuracies, since it is easier to classify only one concept at a time instead of all of them combined.\\

We do know that the i.i.d. precondition, necessary for the validity of statistics obtained from bootstrapped samples, is violated in the setting of streaming data
and that there are some rather theoretical cases in which our approach does not work. Nonetheless, we see it as a strong indicator for the present drift type in a dataset.\\

\subsubsection{Results of the applied tests}
Next to the real world data we also analyze the drift type in some artificial datasets as a proof of concept. Included as well, is a dataset without any drift named Chessboard i.i.d..
We used 200 bootstrap samples per window size. The accuracy is obtained in the standard online learning setting in which each incoming example is first classified and 
afterwards used for training (often called ``Interleaved test-train``).\\
Table \ref{tab:drifttype} shows the mean accuracies of the bootstrapped samples with corresponding standard deviations and the inferred drift type after the respective tests. 
Our approach correctly classifies the drift type of all artificial datasets emphasizing its practical relevance. 
In the case of artificial datasets the increase / decrease of performance with shrinking window sizes is quite significant for datasets
with / without real drift. This is generally less pronounced for real real world data. Nonetheless, the datasets Elec2, Outdoor and Rialto clearly benefit from smaller window sizes. 
Covtype contains little real drift, while the Weather task incorporates only virtual drift.
\begin{table*}
\caption{Mean accuracies and corresponding standard deviations obtained from bootstrapped samples of the datasets with varying sliding window sizes.}
\label{tab:drifttype}
\centering
\subfloat[Stage 1: Mean accuracies resulted by evaluating bootstrapped samples with various different window sizes. Values achieved with restricted windows which are significantly higher compared to those without restriction are marked bold. 
A dataset contains real drift if this is the case for at least one size.]{
\begin{tabular}{l|ccccccc}
\textit{Dataset} & KNN\textsubscript{S-100}&KNN\textsubscript{S-500}&KNN\textsubscript{S-1000}&KNN\textsubscript{S-5000}&KNN\textsubscript{S-10000}&KNN&Concluded drift type\\\hline
Weather              &82.03(0.12)&84.05(0.24)&84.36(0.25)&84.95(0.18)&84.92(0.20)&84.86(0.16)&not real\\
Elec2                &\textbf{89.08(0.18)}&\textbf{87.46(0.17)}&\textbf{86.61(0.16)}&\textbf{85.07(0.11)}&\textbf{84.22(0.14)}&83.43(0.13)&real\\
Cover Type           &94.65(0.01)&96.15(0.01)&\textbf{97.11(0.01)}&\textbf{96.95(0.01)}&\textbf{96.92(0.01)}& 5&real\\
Outdoor              &89.08(0.18)&87.46(0.17)&86.61(0.16)&85.07(0.11)&84.22(0.14)&83.43(0.13)&real\\
Railto               &89.08(0.18)&87.46(0.17)&86.61(0.16)&85.07(0.11)&84.22(0.14)&83.43(0.13)&real\\\hline
Chessboard i.i.d.    &63.23(0.07)&83.63(0.07)&88.47(0.06)&94.67(0.03)&96.15(0.04)&98.37(0.02)& not real\\
Transient Chessboard &81.00(0.05)&88.56(0.04)&88.85(0.04)&94.81(0.02)&95.89(0.03)&98.36(0.03)& not real\\
Moving Squares       &\textbf{97.73(0.02)}&\textbf{67.22(0.05)}&\textbf{63.30(0.05)}&56.87(0.11)&57.22(0.04)&57.12(0.10)& real\\
Interchanging RBF    &97.73(0.02)&67.22(0.05)&63.30(0.05)&56.87(0.11)&57.22(0.04)&57.12(0.10)& real\\
\end{tabular}
}
\par\vspace{5 pt}
\subfloat[Stage 2: Mean accuracies resulted by evaluating permuted, bootstrapped samples with various different window sizes. 
Values which are significantly higher compared to those achieved in a) with the same window size are marked bold.
Virtual drift is incorporated within a dataset when this is the case for at least one size.]{
\begin{tabular}{l|ccccccc}
\textit{Dataset} & KNN\textsubscript{S-100}&KNN\textsubscript{S-500}&KNN\textsubscript{S-1000}&KNN\textsubscript{S-5000}&KNN\textsubscript{S-10000}&KNN&Concluded drift type\\\hline
\rule{0pt}{8pt}
Weather              &\textbf{81.14(0.30)}&\textbf{83.20(0.23)}&83.89(0.28)&84.42(0.17)&84.77(0.19)&84.63(0.18)&virtual\\\hline
Chessboard i.i.d.    &63.25(0.05)&83.63(0.06)&88.44(0.06)&94.71(0.04)&96.18(0.02)&98.36(0.01)&None\\
Transient Chessboard &\textbf{63.30(0.09)}&\textbf{83.77(0.06)}&\textbf{88.48(0.05)}&94.77(0.03)&96.20(0.05)&98.38(0.02)&virtual\\
\end{tabular}
}
\end{table*}

\section{Results}
We evaluated the methods by measuring the Interleaved test-train accuracy. The error rates of all experiments are shown
in Table \ref{tab:result}.\\
\begin{table*}
\caption{Error rates of all experiments evaluated with the Interleaved Test-Then-Train method.}
\label{tab:result}
\centering
\begin{tabular}{l|ccccccc}
Dataset & HT\textsubscript{A} & LPPNSE &DACC& LVGB & kNN\textsubscript{S} & kNN\textsubscript{W\textsubscript{A}}& kNN\textsubscript{M}\\\hline
SEA Concepts & 13.8 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\
HYP & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\ 
MRBF & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\
IRBF & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\
SQR & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\
CHESS & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\
MIX & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\\hline
Art. avg & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\\hline
Art. rank & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\\hline
Weather & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\
Elec & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\
CovType & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\
Outdoor & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\
Railto & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\\hline
Real avg& 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\\hline
Real rank& 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\\hline
total avg& 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\\hline
total rank& 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00 & 10.00\\\hline
\end{tabular}
\end{table*}
(XXVL name of algorithm) outperforms the other algorithms quite significantly by having nearly half the error rate in average compared to the second best method LVGB. 
Even more important is in our eyes the fact that while all other methods are struggling at some datasets our approach delivers very robust results without any hiccup. All drift types are handled
better or at least competitive compared to the other algorithms. This is particularly clarified in the large accuracy gap achieved with the MIX dataset, which contains incremental, 
abrupt and virtual drift at the same time. \\
The methodically most similar method to ours is kNN\textsubscript{W\textsubscript{A}}, since it uses also kNN as classifier and actively manages its window.
However, it performs in all experiments worse, even in those containing only abrupt drift.\\
Our results confirm the fact that kNN is in general a very competitive algorithm in the streaming setting. It is quite surprising that the simple sliding window approach of fixed window size
kNN\textsubscript{S} performs comparably well or even better than more sophisticated methods such as HTAdaptive or L++.NSE.

\subsection{Memory behaviour}
In this section we illustrate the adaptation of the STM and LTM as well as the different roles they take on depending on the demands of a given task.
Figure \ref{fig:abrupt} depicts on the left the size adjustment of the STM in case of abrupt drift during the Interchanging RBF experiment. 
\begin{figure}
\centering
	\subfloat{%
	\includegraphics[width=0.24\textwidth]{images/abruptSTMSize.png}
	}
	\subfloat{%
	\includegraphics[width=0.24\textwidth]{images/abruptResp.png}
	}
	\vspace{0 pt}
	\subfloat{%
	\includegraphics[width=0.24\textwidth]{images/abruptSTM.pdf}
	}
	\subfloat{%
	\includegraphics[width=0.24\textwidth]{images/abruptLTM.pdf}
	}
\caption{Figures for Interchanging RBF}
\label{fig:abrupt}
\end{figure}
The algorithm reliably reduces the window size each time after an abrupt drift occurred.
However, we also observe a certain delay during which wrong predictions are likely to be done by the classifier. 
This delay is due to two reasons. Firstly, a certain amount of examples is required to construct a sufficiently well performing classifier for the new concept. Secondly,
the more examples of the former concept are contained in the short term memory, the more stable is the corresponding classifier and the more examples of the 
new concept are required to deteriorate its overall accuracy. Hence, the delay illustrates a self-adjusting natural trade-off between adaption speed
to new concepts and the robustness against noise, governed by the stability of both concepts.\\
The consolidation of the LTM is also visible in Figure \ref{fig:abrupt}. All samples which were interfering with the STM were deleted, and therefore the feature space is empty there. 
Whereas the harmless samples around the empty spots are kept in the memory.\\
As already mentioned the Moving Squares dataset is constructed in such a way that the squares may overlap each other if more than 120 of the recent samples are kept in memory. Hence,
the best strategy for this problem is to keep the memory as small as possible and to use only the most recent examples for prediction. 

\begin{figure}
\centering
	\subfloat{%
	\includegraphics[width=0.24\textwidth]{images/squaresSTMSize.png}
	}
	\subfloat{%
	\includegraphics[width=0.24\textwidth]{images/squaresResp.png}
	}
	\vspace{0 pt}
	\subfloat{%
	\includegraphics[width=0.24\textwidth]{images/squaresSTM.pdf}
	}
	\subfloat{%
	\includegraphics[width=0.24\textwidth]{images/squaresLTM.pdf}
	}
\caption{Figures for Moving Squares}
\label{fig:squares}
\end{figure}
As can be seen in figure \ref{fig:squares}, the size of the STM is most of the time kept between 50 and 100 samples, allowing a nearly perfect prediction. 
As desired, the samples do not overlap each other within the STM as can be seen in its snapshot. 
The reason that the window is usually reduced precisely at 100 examples is that the default parameter for the minimal size of the STM is set to 50. Therefore,
even better results are possible if the minimal size is further reduced.\\
In contrast to the previous two datasets which basically do not require the LTM, we see in figure \ref{fig:chess} its importance during the prediction of the Transient Chessboard task.
\begin{figure}
\centering
	\subfloat{%
	\includegraphics[width=0.24\textwidth]{images/chessSTMSize.png}
	}
	\subfloat{%
	\includegraphics[width=0.24\textwidth]{images/chessResp.png}
	}
	\vspace{0 pt}
	\subfloat{%
	\includegraphics[width=0.24\textwidth]{images/chessSTM.pdf}
	}
	\subfloat{%
	\includegraphics[width=0.24\textwidth]{images/chessLTM.pdf}
	}
\caption{Figures for T}
\label{fig:chess}
\end{figure}
The STM is used alone whenever the data is presented square by square XXVL formulate reason. But in the phases introducing samples distributed over the whole board, the LTM
is heavily used since it contains beneficial information from the past. The LTM snapshot reveals that the whole chessboard is preserved in a compressed fashion.\\
A further example for the task dependent relevance of the LTM and STM, this time concerning real world data, is depicted in Fig.\ref{fig:realResp}. 
While the LTM is heavily used in the virtual drift dataset Weather, it is mainly neglected in the Rialto problem.
\begin{figure}
\centering
	\subfloat{%
	\includegraphics[width=0.24\textwidth]{images/rialtoResp.png}
	}
	\subfloat{%
	\includegraphics[width=0.24\textwidth]{images/weatherResp.png}
	}
\caption{Figures for T}
\label{fig:realResp}
\end{figure}

\section{Conclusion}

\newpage

% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,Drift}

% that's all folks
\end{document}

\iffalse
ToDo:
-add proper labels for responsibility plots, try to make it more clear
-add in pictures of transient chessboard phases of partially revealed and full revealed, for STM and Resp Plot
-add in pictures of abrupt drift, the times when drift occurs to highlight the delay
-find different snapshot for transient Chessboard, highlighting the compression more


\begin{equation*}
m_i = m_{i_1}/2
STM_i=\{x_t,...x_{t-m_i}| x_i \in \mathbb{R}^n\}.
\end{equation*}

$\Psi=\{STM_1...STM_k|STM_i=STM_{i-1}[:|STM_{i-1}|/2]\}$ of k .

$\Psi=\{STM_1...STM_k|STM_i=\{x_t,...x_{t-m_i} | mi$ of k 

\begin{equation*}
K = \{k_1, k_2...k_m | |k_1|=n, |k_i| = 2*|k_{i+1}| \forall i \in \{1..m-1\}\}
\end{equation*}
\begin{equation*}
\Psi=\{STM_1...STM_k|STM_i=\{x_t,...x_{t-m_i}|m_i = \frac{m_{i-1}}{2}\},
\end{equation*}