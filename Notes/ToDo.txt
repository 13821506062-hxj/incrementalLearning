
LVQ:
-Insertion regularisierung ausprobieren
-Retraining-Effect zusammenschreiben
-Retraining auf Fenster solange wiederholen bis Testfehler nicht kleiner wird. Ausprobieren


-Konvergiert LVQ gegen Bayes Optimum, mit Barbara besprechen
-Wie verhaelt sich LVQ bei ueberlappenden Regionen (offline/ online)


SamplingCost
-Sampling fuer Insertions aendern zufaellig ohne zuruecklegen(Roulette Sampling mit funktion). Eventuell bereits beim vorherigen mal ausprobierte Samples bestrafen.

-finden einer sinnvollen deletion Strategy, funktioniert eigentlich wenn alle Datensaetze betrachtet werden. Eventuell wieder mit Testfehler auf dem Fenster, solange zuf√§llig prototypen
rausnehmen, solange testfehler besser wird.




-relsim-wachstum fuer SoftLVQ (mit Barbara nochmals reden)

SoftwareQuality:
-unitTests wieder in ordnung bringen fuer 2.0
-unitTests in 1.0 integrieren
-Stratifield trainTestSplit, oldDatasetPreparations like randomRegular etc. umstellen auf CV
-Integration of naiveNN and SVM in LVQExperiment, abstraction of classifier....
-save von GLVQs






Ideas:
-Ensemble of LVQs testen
-For Classifier combination localization by getting nearest Prototype in the online model(or several of them) to have a local confidence estimation,
confidence estimation should be based on statistics probably

